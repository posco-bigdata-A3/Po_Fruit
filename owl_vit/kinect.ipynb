{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63317af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting kinect.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile kinect.py\n",
    "\n",
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image  # 이미지를 다루기 위한 라이브러리\n",
    "import time\n",
    "\n",
    "# 카메라로 인식한 워크스페이스를 아래 범위에 따라 자름. \n",
    "WS_PC = [180, 360, 300, 620]  # -> [y축 시작, y축 끝, x축 시작, x축 끝]\n",
    "\n",
    "# RealSense 카메라를 사용하여 이미지를 수집하고, 수집된 이미지를 실시간으로 시각화\n",
    "def get_workspace_crop(img):\n",
    "    retval = img[WS_PC[0]:WS_PC[1], WS_PC[2]:WS_PC[3], ...]\n",
    "    return retval\n",
    "\n",
    "\n",
    "class RealSenseClient:\n",
    "    def __init__(self):\n",
    "        self.pipeline = rs.pipeline()\n",
    "        self.config = rs.config()\n",
    "        self.config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)\n",
    "        self.config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)\n",
    "        self.pipeline.start(self.config) # 파이프라인 시작\n",
    "\n",
    "    def get_camera_data(self):\n",
    "        # 프레임 기다렸다가 컬러, 깊이 프레임 가져오기\n",
    "        frames = self.pipeline.wait_for_frames()\n",
    "        color_frame = frames.get_color_frame()\n",
    "        depth_frame = frames.get_depth_frame()\n",
    "\n",
    "        # 프레임 못 가져오면 color_image, depth_image 모두 None으로 반환\n",
    "        if not color_frame or not depth_frame:\n",
    "            return None, None \n",
    "\n",
    "        # 받아온 이미지를 처리할 수 있도록 array로 변환\n",
    "        color_image = np.asanyarray(color_frame.get_data())\n",
    "        depth_image = np.asanyarray(depth_frame.get_data())\n",
    "\n",
    "        # depth image 배열을 meter 단위로 스케일 조정\n",
    "        depth_image = depth_image * 0.001  \n",
    "\n",
    "        return color_image, depth_image\n",
    "\n",
    "    def stop(self):\n",
    "        self.pipeline.stop()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    realsense = RealSenseClient()\n",
    "    \n",
    "    counter = 0\n",
    "    limit = 20\n",
    "    sleep = 0.05\n",
    "    reset_interval = 16  # 스트림을 재설정하는 간격\n",
    "\n",
    "    all_rgbs = []\n",
    "    try:\n",
    "        while counter < limit:\n",
    "            # counter가 reset_interval의 배수이거나, 0이 아닐 때 재설정 -> RealSense 카메라 스트림을 중지하고 다시 시작하는 과정\n",
    "            if counter % reset_interval == 0 and counter != 0:\n",
    "                realsense.stop()\n",
    "                time.sleep(1)  # 스트림이 완전히 종료되도록 잠시 대기\n",
    "                realsense = RealSenseClient()\n",
    "            \n",
    "            color_im, depth_im = realsense.get_camera_data()\n",
    "            if color_im is None or depth_im is None:\n",
    "                continue\n",
    "\n",
    "            # numpy 배열 형태의 이미지를 PIL 이미지 객체로 변환 -> 이미지 파일로 저장, 이미지를 화면에 표시 \n",
    "            # im = Image.fromarray(img)\n",
    "            \n",
    "            print(\"img shape: \", color_im.shape)\n",
    "            print(\"depth shape: \", depth_im.shape)\n",
    "            counter += 1\n",
    "            time.sleep(sleep)\n",
    "            print('Step counter at {}'.format(counter))\n",
    "            all_rgbs.append(color_im)\n",
    "\n",
    "            fig, ax = plt.subplots(2, 2, figsize=(10, 5))\n",
    "        \n",
    "            plt.show()\n",
    "    finally:\n",
    "        realsense.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "804272d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0+cu102\n",
      "10.2\n",
      "7605\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.backends.cudnn.version())\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74823424-0c09-4d9c-9db9-284da83ffd98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7605\n"
     ]
    }
   ],
   "source": [
    "print(torch.backends.cudnn.version())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625a4c0b-4317-48d9-b4e9-56483e61fee2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch171",
   "language": "python",
   "name": "pytorch171"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
